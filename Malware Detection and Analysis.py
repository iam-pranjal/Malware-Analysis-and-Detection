#!/usr/bin/env python
# coding: utf-8

# In[1]:


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


# ## 2 Scenario 1 : 

# ##### 2.1 Attack to Benign ratio: 10 to 90 

# In[2]:


df = pd.read_csv(r"D:\Mini Project 2\data\BitcoinHeistData.csv")


# In[3]:


df=df.drop(range(10000,40000))


# In[4]:


df.shape


# In[5]:


df=df.drop(range(100000,2886697))


# In[6]:


df.shape


# In[7]:


df.head()


# In[8]:


df=df.sample(frac=1).reset_index(drop=True)


# In[9]:


df.head()


# In[10]:


y=df['label']


# In[11]:


y.head()


# In[12]:


df.head()


# In[13]:


from sklearn.preprocessing import LabelEncoder


# In[14]:


le_address = LabelEncoder()


# In[15]:


le_label = LabelEncoder()


# In[16]:


df['address_n']=le_address.fit_transform(df['address'])
df['label_n']=le_label.fit_transform(df['label'])


# In[17]:


df.head()


# In[18]:


y1=df['label_n']


# In[19]:


y1.head


# In[20]:


df=df.drop(['address'],axis=1)
df=df.drop(['label'],axis=1)


# In[21]:


df.head()


# In[22]:


df.shape


# In[24]:


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(df,y1,test_size=0.2,random_state=42)


# In[28]:


from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score
from sklearn.metrics import plot_confusion_matrix,confusion_matrix,classification_report


# ### 2.2 1-Random Forest
#  

# In[29]:


from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
clf = RandomForestClassifier(max_depth=2,random_state=0)
randomModel = clf.fit(x_train,y_train)


# ##### Model Evaluation

# In[30]:


#Accuracy on the train dataset
train_pred = randomModel.predict(x_train)
accuracy_score(y_train,train_pred)


# In[31]:


#Accuracy on test dataset
prediction = randomModel.predict(x_test)
accuracy_score(y_test,prediction)


# In[32]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, prediction, average='micro')


# In[33]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, prediction, average='micro')


# In[34]:


f1_score(y_test,prediction,average='micro')


# ##### Confusion Matrix

# In[38]:


conf_matrix = confusion_matrix(y_test,prediction)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, prediction,zero_division=0))


# ### 2.3 2-Logistic regression

# In[39]:


from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(random_state=0)
logModel=clf.fit(x_train,y_train)


# ##### Model Evaluation

# In[40]:


#Accuracy on the train dataset
train_log=logModel.predict(x_train)
accuracy_score(y_train,train_log)


# In[41]:


#Accuracy on the test dataset
pred=logModel.predict(x_test)
accuracy_score(y_test,pred)


# In[42]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred, average='micro')


# In[43]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred, average='micro')


# In[44]:


f1_score(y_test,pred,average='weighted')


# ##### Confusion Matrix

# In[63]:


conf_matrix = confusion_matrix(y_test,pred)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, pred, zero_division=0))


# ### 2.4 3-Decision Tree

# In[46]:


from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(criterion="gini", random_state=42,max_depth=3,min_samples_leaf=5)
DecisionModel=clf.fit(x_train,y_train)


# In[47]:


from sklearn.metrics import classification_report


# ##### Model Evaluation 

# In[48]:


#Accuracy on the train dataset
train_decision=DecisionModel.predict(x_train)
accuracy_score(y_train,train_decision)


# In[49]:


#Accuracy on the test dataset
pred_dec=DecisionModel.predict(x_test)
accuracy_score(y_test,pred_dec)


# In[50]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred_dec, average='micro')


# In[51]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred_dec, average='micro')


# In[52]:


f1_score(y_test,pred_dec,average='weighted')


# ##### Confusion Matrix

# In[53]:


conf_matrix = confusion_matrix(y_test,pred_dec)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')
        
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print(classification_report(y_test, pred_dec,zero_division=0))


# ### 2.5 4-K-NN

# In[54]:


from sklearn.neighbors import KNeighborsClassifier


# In[55]:


knn = KNeighborsClassifier(n_neighbors=7)


# In[56]:


knn.fit(x_train, y_train)


# In[57]:


#Accuracy on the test dataset
pred_knn=knn.predict(x_test)
accuracy_score(y_test,pred_knn)


# In[58]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred_knn, average='micro')


# In[59]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred_knn, average='micro')


# In[62]:


conf_matrix = confusion_matrix(y_test,pred_knn)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')
        
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print(classification_report(y_test, pred_knn, zero_division=0))


# ## 3 Scenario 2 : 

# ##### 3.1 Attack to Benign ratio: 20 to 80

# In[64]:


df = pd.read_csv(r"D:\Mini Project 2\data\BitcoinHeistData.csv")


# In[65]:


df=df.drop(range(20000,40000))


# In[66]:


df.shape


# In[67]:


df=df.drop(range(100000,2896697))


# In[68]:


df.shape


# In[69]:


df.head()


# In[70]:


df=df.sample(frac=1).reset_index(drop=True)


# In[71]:


df.head()


# In[72]:


y=df['label']


# In[73]:


y.head()


# In[74]:


df.head()


# In[75]:


from sklearn.preprocessing import LabelEncoder


# In[76]:


le_address = LabelEncoder()


# In[77]:


le_label = LabelEncoder()


# In[78]:


df['address_n']=le_address.fit_transform(df['address'])
df['label_n']=le_label.fit_transform(df['label'])


# In[79]:


df.head()


# In[80]:


y1=df['label_n']


# In[81]:


y1.head


# In[82]:


df=df.drop(['address'],axis=1)
df=df.drop(['label'],axis=1)


# In[83]:


df.head()


# In[84]:


df.shape


# In[85]:


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(df,y1,test_size=0.2,random_state=42)


# In[86]:


x_train.shape


# In[87]:


from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score
from sklearn.metrics import plot_confusion_matrix,confusion_matrix,classification_report


# ### 3.2 1-Random Forest
# 

# In[88]:


from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
clf = RandomForestClassifier(max_depth=2,random_state=0)
randomModel = clf.fit(x_train,y_train)


# ##### Model Evaluation 

# In[89]:


#Accuracy on the train dataset
train_pred = randomModel.predict(x_train)
accuracy_score(y_train,train_pred)


# In[90]:


#Accuracy on test dataset
prediction = randomModel.predict(x_test)
accuracy_score(y_test,prediction)


# In[91]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, prediction, average='micro')


# In[92]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, prediction, average='micro')


# In[93]:


f1_score(y_test,prediction,average='micro')


# ##### Confusion Matrix 

# In[94]:


conf_matrix = confusion_matrix(y_test,prediction)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, prediction,zero_division=0))


# ### 3.3 2-Logistic regression 

# In[95]:


from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(random_state=0)
logModel=clf.fit(x_train,y_train)


# ##### Model Evaluation

# In[96]:


#Accuracy on the train dataset
train_log=logModel.predict(x_train)
accuracy_score(y_train,train_log)


# In[97]:


#Accuracy on the test dataset
pred=logModel.predict(x_test)
accuracy_score(y_test,pred)


# In[98]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred, average='micro')


# In[99]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred, average='micro')


# In[100]:


f1_score(y_test,pred,average='weighted')


# ##### Confusion Matrix 

# In[101]:


conf_matrix = confusion_matrix(y_test,pred)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, pred, zero_division=0))


# ### 3.4 3-Decision Tree

# In[102]:


from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(criterion="gini", random_state=42,max_depth=3,min_samples_leaf=5)
DecisionModel=clf.fit(x_train,y_train)


# In[103]:


from sklearn.metrics import classification_report


# ##### Model Evaluation 

# In[104]:


#Accuracy on the train dataset
train_decision=DecisionModel.predict(x_train)
accuracy_score(y_train,train_decision)


# In[105]:


#Accuracy on the test dataset
pred_dec=DecisionModel.predict(x_test)
accuracy_score(y_test,pred_dec)


# In[106]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred_dec, average='micro')


# In[107]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred_dec, average='micro')


# In[108]:


f1_score(y_test,pred_dec,average='weighted')


# ##### Confusion Matrix 

# In[109]:


conf_matrix = confusion_matrix(y_test,pred_dec)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')
        
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print(classification_report(y_test, pred_dec,zero_division=0))


# ### 3.5 4-K-NN

# In[110]:


from sklearn.neighbors import KNeighborsClassifier


# In[111]:


knn = KNeighborsClassifier(n_neighbors=7)


# In[112]:


knn.fit(x_train, y_train)


# In[113]:


#Accuracy on the test dataset
pred_knn=knn.predict(x_test)
accuracy_score(y_test,pred_knn)


# In[114]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred_knn, average='micro')


# In[115]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred_knn, average='micro')


# In[116]:


conf_matrix = confusion_matrix(y_test,pred_knn)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')
        
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

print(classification_report(y_test, pred_knn, zero_division=0))


# ## 4 Scenario 3 : 

# ##### 4.1 Attack to Benign ratio: 30 to 70 

# In[119]:


df = pd.read_csv(r"D:\Mini Project 2\data\BitcoinHeistData.csv")


# In[120]:


df=df.drop(range(30000,40000))


# In[121]:


df.shape


# In[122]:


df=df.drop(range(100000,2906697))


# In[123]:


df.shape


# In[124]:


df.head()


# In[125]:


df=df.sample(frac=1).reset_index(drop=True)


# In[126]:


df.head()


# In[127]:


y=df['label']


# In[128]:


y.head()


# In[129]:


df.head()


# In[130]:


from sklearn.preprocessing import LabelEncoder


# In[131]:


le_address = LabelEncoder()


# In[132]:


le_label = LabelEncoder()


# In[133]:


df['address_n']=le_address.fit_transform(df['address'])
df['label_n']=le_label.fit_transform(df['label'])


# In[134]:


df.head()


# In[135]:


y1=df['label_n']


# In[136]:


y1.head


# In[137]:


df=df.drop(['address'],axis=1)
df=df.drop(['label'],axis=1)


# In[138]:


df.head()


# In[139]:


df.shape


# In[140]:


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(df,y1,test_size=0.2,random_state=42)


# In[141]:


x_train.shape


# In[142]:


from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score
from sklearn.metrics import plot_confusion_matrix,confusion_matrix,classification_report


# ### 4.2 1-Random Forest 

# In[143]:


from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
clf = RandomForestClassifier(max_depth=2,random_state=0)
randomModel = clf.fit(x_train,y_train)


# ##### Model Evaluation 

# In[144]:


#Accuracy on the train dataset
train_pred = randomModel.predict(x_train)
accuracy_score(y_train,train_pred)


# In[145]:


#Accuracy on test dataset
prediction = randomModel.predict(x_test)
accuracy_score(y_test,prediction)


# In[146]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, prediction, average='micro')


# In[147]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, prediction, average='micro')


# In[148]:


f1_score(y_test,prediction,average='micro')


# ##### Confusion Matrix 

# In[149]:


conf_matrix = confusion_matrix(y_test,prediction)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, prediction,zero_division=0))


# ### 4.3 2-Logistic regression

# In[150]:


from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(random_state=0)
logModel=clf.fit(x_train,y_train)


# In[151]:


#Accuracy on the train dataset
train_log=logModel.predict(x_train)
accuracy_score(y_train,train_log)


# In[152]:


#Accuracy on the test dataset
pred=logModel.predict(x_test)
accuracy_score(y_test,pred)


# In[153]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred, average='micro')


# In[154]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred, average='micro')


# In[155]:


f1_score(y_test,pred,average='weighted')


# ##### Confusion Matrix 

# In[157]:


conf_matrix = confusion_matrix(y_test,pred)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, pred, zero_division=0))


# ### 4.4 3-Decision Tree 

# In[158]:


from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(criterion="gini", random_state=42,max_depth=3,min_samples_leaf=5)
DecisionModel=clf.fit(x_train,y_train)


# In[159]:


from sklearn.metrics import classification_report


# ##### Model Evaluation 

# In[160]:


#Accuracy on the train dataset
train_decision=DecisionModel.predict(x_train)
accuracy_score(y_train,train_decision)


# In[161]:


#Accuracy on the test dataset
pred_dec=DecisionModel.predict(x_test)
accuracy_score(y_test,pred_dec)


# In[162]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred_dec, average='micro')


# In[163]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred_dec, average='micro')


# In[164]:


f1_score(y_test,pred_dec,average='weighted')


# ##### Confusion Matrix 

# In[165]:


conf_matrix = confusion_matrix(y_test, pred_dec)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, pred_dec, zero_division=0))


# ### 4.5 4-K-NN 

# In[166]:


from sklearn.neighbors import KNeighborsClassifier


# In[167]:


knn = KNeighborsClassifier(n_neighbors=7)


# In[168]:


knn.fit(x_train, y_train)


# In[169]:


#Accuracy on the test dataset
pred_knn=knn.predict(x_test)
accuracy_score(y_test,pred_knn)


# In[170]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred_knn, average='micro')


# In[171]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred_knn, average='micro')


# In[172]:


conf_matrix = confusion_matrix(y_test, pred_knn)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, pred_knn, zero_division=0))


# ## 5 Scenario 4 :

# ##### 5.1 Attack to Benign ratio: 40 to 60 

# In[173]:


df = pd.read_csv(r"D:\Mini Project 2\data\BitcoinHeistData.csv")


# In[174]:


df.shape


# In[175]:


df=df.drop(range(100000,2916697))


# In[176]:


df.shape


# In[177]:


df.head()


# In[178]:


df=df.sample(frac=1).reset_index(drop=True)


# In[179]:


df.head()


# In[180]:


y=df['label']


# In[181]:


y.head()


# In[182]:


df.head()


# In[183]:


from sklearn.preprocessing import LabelEncoder


# In[184]:


le_address = LabelEncoder()


# In[185]:


le_label = LabelEncoder()


# In[186]:


df['address_n']=le_address.fit_transform(df['address'])
df['label_n']=le_label.fit_transform(df['label'])


# In[187]:


df.head()


# In[188]:


y1=df['label_n']


# In[189]:


y1.head


# In[190]:


df=df.drop(['address'],axis=1)
df=df.drop(['label'],axis=1)


# In[191]:


df.head()


# In[192]:


df.shape


# In[193]:


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(df,y1,test_size=0.2,random_state=42)


# In[194]:


x_train.shape


# In[195]:


from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score
from sklearn.metrics import plot_confusion_matrix,confusion_matrix,classification_report


# ### 5.2 1-Random Forest 

# In[196]:


from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
clf = RandomForestClassifier(max_depth=2,random_state=0)
randomModel = clf.fit(x_train,y_train)


# ##### Model Evaluation 

# In[197]:


#Accuracy on the train dataset
train_pred = randomModel.predict(x_train)
accuracy_score(y_train,train_pred)


# In[198]:


#Accuracy on test dataset
prediction = randomModel.predict(x_test)
accuracy_score(y_test,prediction)


# In[199]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, prediction, average='micro')


# In[200]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, prediction, average='micro')


# In[201]:


f1_score(y_test,prediction,average='micro')


# ##### Confusion Matrix 

# In[202]:


conf_matrix = confusion_matrix(y_test,prediction)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, prediction, zero_division=0))


# ### 5.3 2-Logistic regression 

# In[203]:


from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(random_state=0)
logModel=clf.fit(x_train,y_train)


# ##### Model Evaluation 

# In[204]:


#Accuracy on the train dataset
train_log=logModel.predict(x_train)
accuracy_score(y_train,train_log)


# In[205]:


#Accuracy on the test dataset
pred=logModel.predict(x_test)
accuracy_score(y_test,pred)


# In[206]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred, average='micro')


# In[207]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred, average='micro')


# In[208]:


f1_score(y_test,pred,average='weighted')


# ##### Confusion Matrix

# In[209]:


conf_matrix = confusion_matrix(y_test, pred)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, pred, zero_division=0))


# ### 5.4 3-Decision Tree 

# In[210]:


from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(criterion="gini", random_state=42,max_depth=3,min_samples_leaf=5)
DecisionModel=clf.fit(x_train,y_train)


# In[211]:


from sklearn.metrics import classification_report


# ##### Model Evaluation 

# In[212]:


#Accuracy on the train dataset
train_decision=DecisionModel.predict(x_train)
accuracy_score(y_train,train_decision)


# In[213]:


#Accuracy on the test dataset
pred_dec=DecisionModel.predict(x_test)
accuracy_score(y_test,pred_dec)


# In[214]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred_dec, average='micro')


# In[215]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred_dec, average='micro')


# In[216]:


f1_score(y_test,pred_dec,average='weighted')


# ##### Confusion Matrix 

# In[217]:


conf_matrix = confusion_matrix(y_test, pred_dec)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, pred_dec, zero_division=0))


# ### 5.5 4-K-NN 

# In[218]:


from sklearn.neighbors import KNeighborsClassifier


# In[219]:


knn = KNeighborsClassifier(n_neighbors=7)


# In[220]:


knn.fit(x_train, y_train)


# In[221]:


#Accuracy on the test dataset
pred_knn=knn.predict(x_test)
accuracy_score(y_test,pred_knn)


# In[222]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred_knn, average='micro')


# In[223]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred_knn, average='micro')


# In[224]:


conf_matrix = confusion_matrix(y_test, pred_knn)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, pred_knn, zero_division=0))


# ## 6 Scenario 5 : 

# ##### 6.1 Full Dataset (Total=2916697, Ransomware=41413, Benign=2875284) 

# In[225]:


df = pd.read_csv(r"D:\Mini Project 2\data\BitcoinHeistData.csv")


# In[226]:


df.shape


# In[227]:


df.head()


# In[228]:


df=df.sample(frac=1).reset_index(drop=True)


# In[229]:


df.head()


# In[230]:


y=df['label']


# In[231]:


y.head()


# In[232]:


df.head()


# In[233]:


from sklearn.preprocessing import LabelEncoder


# In[234]:


le_address = LabelEncoder()


# In[235]:


le_label = LabelEncoder()


# In[236]:


df['address_n']=le_address.fit_transform(df['address'])
df['label_n']=le_label.fit_transform(df['label'])


# In[237]:


df.head()


# In[238]:


y1=df['label_n']


# In[239]:


y1.head


# In[240]:


df=df.drop(['address'],axis=1)
df=df.drop(['label'],axis=1)


# In[241]:


df.head()


# In[242]:


df.shape


# In[243]:


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(df,y1,test_size=0.2,random_state=42)


# In[244]:


x_train.shape


# In[245]:


from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score
from sklearn.metrics import plot_confusion_matrix,confusion_matrix,classification_report


# ### 6.2 1-Random Forest 

# In[246]:


from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
clf = RandomForestClassifier(max_depth=2,random_state=0)
randomModel = clf.fit(x_train,y_train)


# ##### Model Evaluation 

# In[247]:


#Accuracy on the train dataset
train_pred = randomModel.predict(x_train)
accuracy_score(y_train,train_pred)


# In[248]:


#Accuracy on test dataset
prediction = randomModel.predict(x_test)
accuracy_score(y_test,prediction)


# In[249]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, prediction, average='micro')


# In[250]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, prediction, average='micro')


# In[251]:


f1_score(y_test,prediction,average='micro')


# ##### Confusion Matrix 

# In[252]:


conf_matrix = confusion_matrix(y_test, prediction)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, prediction, zero_division=0))


# ### 6.3 2-Logistic regression 

# In[254]:


from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(random_state=0)
logModel=clf.fit(x_train,y_train)


# ##### Model Evaluation 

# In[255]:


#Accuracy on the train dataset
train_log=logModel.predict(x_train)
accuracy_score(y_train,train_log)


# In[256]:


#Accuracy on the test dataset
pred=logModel.predict(x_test)
accuracy_score(y_test,pred)


# In[257]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred, average='micro')


# In[258]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred, average='micro')


# In[259]:


f1_score(y_test,pred,average='weighted')


# ##### Confusion Matrix 

# In[260]:


conf_matrix = confusion_matrix(y_test, pred)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, pred, zero_division=0))


# ### 6.4 3-Decision Tree 

# In[261]:


from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(criterion="gini", random_state=42,max_depth=3,min_samples_leaf=5)
DecisionModel=clf.fit(x_train,y_train)


# In[262]:


from sklearn.metrics import classification_report


# ##### Model Evaluation 

# In[263]:


#Accuracy on the train dataset
train_decision=DecisionModel.predict(x_train)
accuracy_score(y_train,train_decision)


# In[264]:


#Accuracy on the test dataset
pred_dec=DecisionModel.predict(x_test)
accuracy_score(y_test,pred_dec)


# In[265]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred_dec, average='micro')


# In[266]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred_dec, average='micro')


# In[267]:


f1_score(y_test,pred_dec,average='weighted')


# ##### Confusion Matrix 

# In[268]:


conf_matrix = confusion_matrix(y_test, pred_dec)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, pred_dec, zero_division=0))


# ### 6.5 4-K-NN 

# In[269]:


from sklearn.neighbors import KNeighborsClassifier


# In[270]:


knn = KNeighborsClassifier(n_neighbors=7)


# In[271]:


knn.fit(x_train, y_train)


# In[272]:


#Accuracy on the test dataset
pred_knn=knn.predict(x_test)
accuracy_score(y_test,pred_knn)


# In[273]:


#Precision Score = TP / (FP + TP)
precision_score(y_test, pred_knn, average='micro')


# In[274]:


#Recall Score = TP / (FN + TP) OR Senstivity
recall_score(y_test, pred_knn, average='micro')


# In[275]:


conf_matrix = confusion_matrix(y_test, pred_knn)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(9, 9))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
   for j in range(conf_matrix.shape[1]):
       ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center',size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
print(classification_report(y_test, pred_knn, zero_division=0))


# In[ ]:




